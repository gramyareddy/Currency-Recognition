{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow.python.keras\n",
    "import os.path as path\n",
    "from scipy import misc\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image\n",
    "from keras.models import Sequential,Model,save_model\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import Adam\n",
    "from keras import applications\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, GlobalAvgPool2D, GlobalMaxPool2D, Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 224, 224, 3)\n",
      "(392, 224, 224, 3)\n",
      "(650, 224, 224, 3)\n",
      "(650, 3)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "images= []\n",
    "i=0\n",
    "#input image as arrays and labels\n",
    "file_paths = glob.glob(\"C:\\MyLearnings\\DeepLearning\\Currency\\\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\TotalDataset\\\\Rs50\\\\*.jpeg\")\n",
    "for image in file_paths:\n",
    "    im = Image.open(image)\n",
    "    images.append(np.asarray(im)) #.transpose(1, 0, 2))\n",
    "    labels.append(1)\n",
    "    i+=1\n",
    "\n",
    "print(np.array(images).shape)\n",
    "limiter=0\n",
    "file_paths = glob.glob(\"C:\\MyLearnings\\\\DeepLearning\\\\Currency\\\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\TotalDataset\\\\Rs100\\\\*.jpeg\")\n",
    "for image in file_paths:\n",
    "    im = Image.open(image)\n",
    "    images.append(np.asarray(im)) #.transpose(1, 0, 2))\n",
    "    labels.append(2)\n",
    "    i+=1\n",
    "\n",
    "print(np.array(images).shape)\n",
    "\n",
    "file_paths = glob.glob(\"C:\\MyLearnings\\\\DeepLearning\\\\Currency\\\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\TotalDataset\\\\Rs500\\\\*.jpeg\")\n",
    "for image in file_paths:\n",
    "    im = Image.open(image)\n",
    "    images.append(np.asarray(im)) #.transpose(1, 0, 2))\n",
    "    labels.append(3)\n",
    "    i+=1\n",
    "\n",
    "print(np.array(images).shape)\n",
    "#one hot encode labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "labels = np.array(labels)\n",
    "labels = labels.reshape(-1,1)\n",
    "labels = onehot_encoder.fit_transform(labels)\n",
    "\n",
    "\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 22,202,435\n",
      "Trainable params: 9,847,555\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#design  model\n",
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n",
    "for layer in model.layers[:17]:\n",
    "    layer.trainable = False\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(4096, activation=\"relu\")(x)\n",
    "predictions = Dense(3, activation=\"softmax\")(x)\n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 520 samples, validate on 130 samples\n",
      "Epoch 1/5\n",
      "520/520 [==============================] - 41s 78ms/step - loss: 4.4036 - accuracy: 0.5788 - val_loss: 1.6709 - val_accuracy: 0.8154\n",
      "Epoch 2/5\n",
      "520/520 [==============================] - 37s 71ms/step - loss: 1.1393 - accuracy: 0.8788 - val_loss: 3.9687 - val_accuracy: 0.7308\n",
      "Epoch 3/5\n",
      "520/520 [==============================] - 38s 73ms/step - loss: 1.4121 - accuracy: 0.9135 - val_loss: 0.6922 - val_accuracy: 0.8769\n",
      "Epoch 4/5\n",
      "520/520 [==============================] - 38s 73ms/step - loss: 0.2775 - accuracy: 0.9712 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "520/520 [==============================] - 38s 73ms/step - loss: 0.2566 - accuracy: 0.9865 - val_loss: 0.1468 - val_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "#compile and fit model\n",
    "history = model_final.fit(np.array(images), labels, epochs=5, validation_split= 0.2,batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-671da45de07e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Saved model to disk\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \"\"\"\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Model\\\\saved_model.h5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "#save models\n",
    "# serialize model to JSON\n",
    "\"\"\"\n",
    "model_json = model_final.to_json()\n",
    "with open(\"C:\\MyLearnings\\DeepLearning\\Currency\\\\Dataset\\\\Resizedcurrency\\\\Model\\\\model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_final.save_weights(\"C:\\MyLearnings\\\\DeepLearning\\\\Currency\\\\Dataset\\\\Resizedcurrency\\\\Model\\\\model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\"\"\"\n",
    "model_final.save_model(\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Model\\\\saved_model.h5\",save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 224, 224, 3)\n",
      "(126, 3)\n",
      "126/126 [==============================] - 10s 77ms/step\n",
      "accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "images_pred= []\n",
    "labels_pred=[]\n",
    "i=0\n",
    "#input image as arrays and labels\n",
    "file_paths = glob.glob(\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\Aug\\\\test\\\\Rs50\\\\*.jpeg\")\n",
    "for image in file_paths:\n",
    "    im = Image.open(image)\n",
    "    images_pred.append(np.asarray(im)) #.transpose(1, 0, 2))\n",
    "    i+=1\n",
    "    labels_pred.append(1)\n",
    "    \n",
    "file_paths = glob.glob(\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\Aug\\\\test\\\\Rs100\\\\*.jpeg\")\n",
    "for image in file_paths:\n",
    "    im = Image.open(image)\n",
    "    images_pred.append(np.asarray(im)) #.transpose(1, 0, 2))\n",
    "    i+=1\n",
    "    labels_pred.append(2)\n",
    "    \n",
    "file_paths = glob.glob(\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\Aug\\\\test\\\\Rs500\\\\*.jpeg\")\n",
    "for image in file_paths:\n",
    "    im = Image.open(image)\n",
    "    images_pred.append(np.asarray(im)) #.transpose(1, 0, 2))\n",
    "    i+=1\n",
    "    labels_pred.append(3)    \n",
    "    \n",
    "    \n",
    "images_pred = np.array(images_pred)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "labels_pred = np.array(labels_pred)\n",
    "labels_pred = labels_pred.reshape(-1,1)\n",
    "labels_pred = onehot_encoder.fit_transform(labels_pred)\n",
    "print(images_pred.shape)\n",
    "print(labels_pred.shape)\n",
    "scores = model_final.evaluate(images_pred,labels_pred,batch_size=8)\n",
    "print(\"%s: %.2f%%\" % (model_final.metrics_names[1], scores[1]*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\test\\\\Rs100\\\\IMG-20200503-WA0038.jpeg\")\n",
    "image_new = np.array(im)\n",
    "image_new = np.expand_dims(image_new, axis=0)\n",
    "\n",
    "print(model_final.predict(image_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\test\\\\Rs50\\\\IMG-20200503-WA0058.jpeg\")\n",
    "image_new = np.array(im)\n",
    "image_new = np.expand_dims(image_new, axis=0)\n",
    "\n",
    "print(model_final.predict(image_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.4342842e-09 1.4946654e-06 9.9999845e-01]]\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"C:\\MyLearnings\\DeepLearning\\Currency\\Dataset\\\\Resizedcurrency\\\\Augmentdata\\\\test\\\\Rs500\\\\IMG-20200503-WA0015.jpeg\")\n",
    "image_new = np.array(im)\n",
    "image_new = np.expand_dims(image_new, axis=0)\n",
    "\n",
    "print(model_final.predict(image_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
